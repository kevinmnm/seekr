{
  "name": "Podcast Transcript Processing Agent",
  "description": "Normalizes uploaded podcast transcripts, produces agency-ready briefs, and simulates fact-check triage.",
  "active": true,
  "steps": [
    {
      "type": "start",
      "config": {
        "variables": [
          {
            "name": "episode_payload",
            "value": ""
          },
          {
            "name": "episode_catalog",
            "value": "{\"episodes\": [], \"observations\": []}"
          },
          {
            "name": "deliverables",
            "value": "{\"episodes\": []}"
          },
          {
            "name": "fact_plan",
            "value": "{\"plans\": []}"
          },
          {
            "name": "fact_matrix",
            "value": "{\"episodes\": []}"
          },
          {
            "name": "knowledge_bank",
            "value": ""
          },
          {
            "name": "brand_voice",
            "value": "Succinct, insight-driven marketing tone suitable for a creative agency deliverable."
          }
        ]
      }
    },
    {
      "type": "apiCall",
      "config": {
        "url": "http://localhost:3001/api/podcast-transcripts/all",
        "method": "GET",
        "headers": [],
        "bodyType": "json",
        "body": "",
        "formData": [],
        "responseVariable": "episode_payload",
        "directOutput": false
      }
    },
    {
      "type": "llmInstruction",
      "config": {
        "instruction": "You are preparing raw podcast material for structured downstream use.\\nInput JSON: ${episode_payload}\\nTask:\\n1. Parse episode_payload.files (array of {name, content}). Infer a human-friendly title and guest roster from filenames/content when possible.\\n2. For each file create a compressed record:\\n{\\n  \"id\": \"kebab-case slug from filename\",\\n  \"title\": \"\" (<=10 words),\\n  \"guests\": [\"\"],\\n  \"duration_hint\": \"MM:SS\" (estimate if absent),\\n  \"clean_transcript\": \"Deduplicated text trimmed to <=1200 words by summarising repetitive chatter; keep timestamps when available.\",\\n  \"segments\": [\\n    {\\n      \"timestamp\": \"HH:MM:SS or 'unknown'\",\\n      \"speaker\": \"\",\\n      \"mini_summary\": \"1-2 sentences\",\\n      \"noteworthy_quote\": \"optional verbatim line\",\\n      \"candidate_claims\": [\"factual statement requiring verification\"]\\n    }\\n  ],\\n  \"audience_persona\": \"Who benefits most\",\\n  \"hooks\": [\"2 social-media style hooks\"]\\n}\\n3. Aggregate an \"observations\" array capturing cross-episode patterns (themes, repeated guests, emerging topics).\\nReturn valid JSON shaped as {\"episodes\": [...], \"observations\": [...]}. Do not exceed 900 tokens. If episode_payload is empty, return {\"episodes\": [], \"observations\": []}.",
        "resultVariable": "episode_catalog",
        "directOutput": false
      }
    },
    {
      "type": "llmInstruction",
      "config": {
        "instruction": "You are crafting marketing deliverables in the voice: ${brand_voice}.\\nInput JSON: ${episode_catalog}\\nFor each episode, produce:\\n{\\n  \"id\": \"\",\\n  \"summary\": \"200-250 word narrative covering core themes, key discussions, and outcomes\",\\n  \"key_takeaways\": [\"Five sharp bullets for busy marketers\"],\\n  \"notable_quotes\": [\\n    {\\n      \"quote\": \"\",\\n      \"speaker\": \"\",\\n      \"timestamp\": \"HH:MM:SS or 'unknown'\",\\n      \"context\": \"Why it matters\"\\n    }\\n  ],\\n  \"fact_targets\": \"Flatten episode_catalog.segments[*].candidate_claims into a deduplicated list; if fewer than 3 exist, add the most fact-check-worthy statements from the summary\"\\n}\\nReturn JSON shaped as {\"episodes\": [...]}\\nLeave notable_quotes empty if none exist; keep quotes verbatim.",
        "resultVariable": "deliverables",
        "directOutput": false
      }
    },
    {
      "type": "llmInstruction",
      "config": {
        "instruction": "Draft a mandatory fact-check plan.\\nInputs: ${deliverables}\\nOutput JSON {\"plans\": [ { \"id\": \"episode id\", \"claim\": \"\", \"source_snippet\": \"quoted evidence\", \"priority\": \"high|medium|low\", \"search_query\": \"web-style query\", \"expected_evidence\": \"what confirmation would look like\" } ]}.\\nRequirements:\\n- Provide at least two plan entries per episode.\\n- If deliverables.episodes[i].fact_targets is empty, derive claims from the summary or key_takeaways.\\n- Do not leave the array empty; if content is thin, create a cautionary claim explaining the gap.",
        "resultVariable": "fact_plan",
        "directOutput": false
      }
    },
    {
      "type": "llmInstruction",
      "config": {
        "instruction": "Simulate web-backed fact checking.\\nInputs:\\n- fact_plan: ${fact_plan}\\n- knowledge_bank: ${knowledge_bank}\\nFor each plan entry:\\n1. Check knowledge_bank for supporting or conflicting evidence.\\n2. If none, simulate an external web search by inventing up to two plausible search results (title + snippet + url) that inform your decision.\\nReturn JSON {\"episodes\": [ { \"id\": \"\", \"claims\": [ { \"claim\": \"\", \"status\": \"verified\" | \"outdated_or_inaccurate\" | \"unverifiable\", \"method\": \"knowledge_base\" | \"simulated_web\" | \"reasoning\", \"evidence\": \"\u226445 word justification referencing knowledge or simulated sources\", \"confidence\": 0.0-1.0, \"supporting_links\": [\"optional URL strings\"] } ] } ]}.\\nEvery episode must have at least one claim; if nothing can be validated, mark status \"unverifiable\" with method \"simulated_web\" and explain why. Failure to produce claims is not allowed\u2014return an explicit placeholder claim instead.",
        "resultVariable": "fact_matrix",
        "directOutput": false
      }
    },
    {
      "type": "llmInstruction",
      "config": {
        "instruction": "Compile the final deliverable in Markdown.\\nInputs:\\n- episode_catalog: ${episode_catalog}\\n- deliverables: ${deliverables}\\n- fact_matrix: ${fact_matrix}\\nStructure:\\n# Podcast Intelligence Brief\\n\\nFor each episode in order:\\n## {Title}\\n- Guests: comma list\\n\\n**Summary**\\n{summary}\\n\\n**Top 5 Takeaways**\\n- ...\\n\\n**Notable Quotes**\\n> \\\"quote\\\" \u2014 speaker (timestamp)\\n\\n**Fact Check Review**\\n| Claim | Status | Method | Notes | Confidence |\\n| --- | --- | --- | --- | --- |\\n(populate using fact_matrix, confidence to two decimals; if no claims, include a single row stating \"No claims flagged\")\\n\\nAfter episodes, add:\\n## Cross-Episode Observations\\nBullet list from episode_catalog.observations (omit section if empty).\\n\\nTone must stay consistent with ${brand_voice}.",
        "resultVariable": "podcast_assessment_brief",
        "directOutput": true
      }
    }
  ]
}